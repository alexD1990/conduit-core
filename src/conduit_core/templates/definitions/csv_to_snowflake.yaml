# GENERATED BY: conduit template csv_to_snowflake
# DESCRIPTION: Import CSV files into Snowflake data warehouse
# LAST UPDATED: 2025-01-15

version: "1.0"
project:
  name: "csv_to_snowflake_pipeline"  # ‚ö†Ô∏è UPDATE THIS
  environment: "production"

sources:
  - type: "csv"
    name: "csv_source"
    config:
      path: "./data/input.csv"        # ‚ö†Ô∏è UPDATE THIS
      delimiter: ","
      has_header: true
      # üí° Auto-detected during first run: columns, data types

destinations:
  - type: "snowflake"
    name: "snowflake_dw"
    config:
      account: "${SNOWFLAKE_ACCOUNT}"        # ‚ö†Ô∏è UPDATE THIS
      user: "${SNOWFLAKE_USER}"
      password: "${SNOWFLAKE_PASSWORD}"      # üîí Use environment variables
      role: "${SNOWFLAKE_ROLE:-SYSADMIN}"
      warehouse: "${SNOWFLAKE_WAREHOUSE}"    # ‚ö†Ô∏è UPDATE THIS
      database: "${SNOWFLAKE_DATABASE}"      # ‚ö†Ô∏è UPDATE THIS
      schema: "${SNOWFLAKE_SCHEMA}"          # ‚ö†Ô∏è UPDATE THIS
      table: "TARGET_TABLE"                  # ‚ö†Ô∏è UPDATE THIS

pipelines:
  - name: "csv_to_snowflake_pipeline"        # ‚ö†Ô∏è UPDATE THIS
    source: "csv_source"
    destination: "snowflake_dw"
    mode: "append"
    quality_checks:
      - column: "id"                         # ‚úÖ Suggested validation
        check: "not_null"
        action: "fail"

# üöÄ HOW TO USE:
# 1. Update all ‚ö†Ô∏è marked fields above.
# 2. Export required env vars for Snowflake credentials.
# 3. Save as `pipeline.yml`.
# 4. Run: `conduit run pipeline.yml`.
