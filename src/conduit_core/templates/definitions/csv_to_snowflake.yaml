# GENERATED BY: conduit template csv_to_snowflake
# DESCRIPTION: Import CSV files into Snowflake data warehouse
# LAST UPDATED: 2025-01-18

version: "1.0"
project:
  name: "csv_to_snowflake_pipeline"  # UPDATE THIS
  environment: "production"

sources:
  - name: "csv_source"
    type: "csv"
    path: "./data/input.csv"        # UPDATE THIS
    delimiter: ","
    has_header: true
    # Auto-detected during first run: columns, data types

destinations:
  - name: "snowflake_dw"
    type: "snowflake"
    account: "${SNOWFLAKE_ACCOUNT}"        # UPDATE THIS
    user: "${SNOWFLAKE_USER}"              # Use environment variables
    password: "${SNOWFLAKE_PASSWORD}"      # Use environment variables
    warehouse: "${SNOWFLAKE_WAREHOUSE}"    # UPDATE THIS
    database: "${SNOWFLAKE_DATABASE}"      # UPDATE THIS
    db_schema: "${SNOWFLAKE_SCHEMA}"       # UPDATE THIS
    table: "target_table"                  # UPDATE THIS

resources:
  - name: "csv_to_snowflake"
    source: "csv_source"
    destination: "snowflake_dw"
    query: ""  # Not used for CSV sources
    mode: "append"
    quality_checks:
      - column: "id"                         # Suggested validation
        check: "not_null"
        action: "fail"

# HOW TO USE:
# 1. Update all marked fields above
# 2. Set environment variables: SNOWFLAKE_ACCOUNT, SNOWFLAKE_USER, SNOWFLAKE_PASSWORD, etc.
# 3. Save as `pipeline.yml`
# 4. Run: `conduit run pipeline.yml`
