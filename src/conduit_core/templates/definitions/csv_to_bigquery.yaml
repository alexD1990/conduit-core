# GENERATED BY: conduit template csv_to_bigquery
# DESCRIPTION: Load CSV files into BigQuery
# LAST UPDATED: 2025-01-18

version: "1.0"
project:
  name: "csv_to_bigquery_pipeline"
  environment: "production"

sources:
  - name: "csv_source"
    type: "csv"
    path: "./data/input.csv"        # UPDATE THIS
    delimiter: ","
    has_header: true

destinations:
  - name: "bigquery_dest"
    type: "bigquery"
    project: "${GCP_PROJECT_ID}"              # UPDATE THIS
    dataset: "analytics"                      # UPDATE THIS
    table: "target_table"                     # UPDATE THIS
    credentials_path: "${GOOGLE_APPLICATION_CREDENTIALS}"  # Service account JSON path
    # location is typically derived from project/dataset; connector may use defaults

resources:
  - name: "csv_to_bigquery"
    source: "csv_source"
    destination: "bigquery_dest"
    query: ""        # Not used for CSV sources
    mode: "append"

# HOW TO USE:
# 1. Update all marked fields above
# 2. Set GOOGLE_APPLICATION_CREDENTIALS to service account JSON path
# 3. Save as `pipeline.yml`
# 4. Run: `conduit run pipeline.yml`
