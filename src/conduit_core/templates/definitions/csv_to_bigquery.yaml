# GENERATED BY: conduit template csv_to_bigquery
# DESCRIPTION: Load CSV files into BigQuery
# LAST UPDATED: 2025-01-15

version: "1.0"
project:
  name: "csv_to_bigquery_pipeline"  # ‚ö†Ô∏è UPDATE THIS
  environment: "production"

sources:
  - type: "csv"
    name: "csv_source"
    config:
      path: "./data/input.csv"      # ‚ö†Ô∏è UPDATE THIS
      delimiter: ","
      has_header: true

destinations:
  - type: "bigquery"
    name: "bq_dw"
    config:
      project: "${BQ_PROJECT_ID}"   # ‚ö†Ô∏è UPDATE THIS
      dataset: "TARGET_DATASET"     # ‚ö†Ô∏è UPDATE THIS
      table: "TARGET_TABLE"         # ‚ö†Ô∏è UPDATE THIS
      credentials_json: "${BQ_SERVICE_ACCOUNT_JSON}"  # üîí

pipelines:
  - name: "csv_to_bigquery_pipeline"
    source: "csv_source"
    destination: "bq_dw"
    mode: "append"
    quality_checks:
      - column: "id"
        check: "not_null"
        action: "fail"

# üöÄ HOW TO USE:
# 1. Update ‚ö†Ô∏è fields.
# 2. Provide BigQuery credentials via env.
# 3. Save as `pipeline.yml`.
# 4. Run: `conduit run pipeline.yml`.
